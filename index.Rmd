---
title: "Machine Learning Project"
author: "Wayne H"
date: "May 10, 2018"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now easy to collect a large amount of data about personal exercise activity.  Data for this project was collected from 6 participants using accelerometers on the belt, forearm, arm, and dumbell. Participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. 

# Project Goal

The goal of this project is to come up with a model that accurately predicts the manner in which participants did the exercise.

# Download and Read Data
```{r message=FALSE}
options(warn=-1)
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(rattle)
options(warn=0)
```
```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile)
}
setwd("./data")

training <- read.csv(("pml-training.csv"), na.strings=c("NA",""))

testing <- read.csv(("pml-testing.csv"), na.strings=c("NA",""))

dim(training)
```

The original data set has `r dim(training)[1]` rows and `r dim(training)[2]` variables

# Clean The Data
```{r}
# Remove first column which is just an index

training <- training[c(-1)]

# Remove columns with more than 50% missing values

training<-training[, -which(colMeans(is.na(training)) > 0.5)]
dim(training)
```

After removing the index column and columns with more than 50% missing values the data set has  `r dim(training)[2]` variables.

```{r}
# Remove variables with little variability

nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[,nzv$nzv==FALSE]
dim(training)
```

After removing columns with little variablility the data set used for analysis has `r dim(training)[1]` rows and `r dim(training)[2]` variables

```{r}
# Need to make sure levels in factor variables are the same 
# in training and testing data sets
common <- intersect(names(training), names(testing)) 
for (p in common) { 
  if (class(training[[p]]) == "factor") { 
    levels(testing[[p]]) <- levels(training[[p]]) 
  } 
}

```

# Split the Training Data Set
```{r}
set.seed(13579)  #set seed for reprodicibility
inTrain <- createDataPartition(training$classe, p=0.60, list=FALSE)
mytrain <- training[inTrain, ]
mytest <- training[-inTrain, ]
```

# Prediction Models

### Tree Prediction

I will first try a simple tree prediction model.

```{r}
modFit1 <- rpart(classe ~ ., data=mytrain, method="class")
fancyRpartPlot(modFit1)
predictions1 <- predict(modFit1, mytest, type = "class")
contree <- confusionMatrix(predictions1, mytest$classe)
contree
```

The estimated accuracy of the prediction for this model is `r paste0(round(contree$overall["Accuracy"] * 100, 3), "%")`. The estimated out-of-sample error is `r paste0(round(100 - contree$overall["Accuracy"] * 100, 3), "%")`.  

The accuracy of this model is too low, so next I will try a random forest model.

### Random Forest Prediction

```{r}
modFit2 <- randomForest(classe ~ ., data=mytrain)
prediction2 <- predict(modFit2, mytest, type = "class")
conrf <- confusionMatrix(prediction2, mytest$classe)
conrf
```

The estimated accuracy of the prediction for this model is `r paste0(round(conrf$overall["Accuracy"], 3), "%")`. The estimated out-of-sample error is `r paste0(round(100 - conrf$overall["Accuracy"]* 100, 3), "%")`.

As the random forest prediction accuracy is very high, no further models will be examined.

# Prediction for the Test Data Set

```{r}
# Apply the model to the test data set

predict(modFit2, testing, type = "class")
```